\chapter{Study 1 - Convolutional architectures}
\label{ch:convolutions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%      EVO Kernels    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evolutionary kernels}

\subsection{Aims}
%Tried to use evol kerns but sparse nature of data means no good
After the results from the Pilot study it was clear the task needed to be reframed.
Previous work using convolutions and kernels as feature detectors suggusted they might be able to provide feature maps necessary for a network to learn.
%Additonally using convolutions would have the advantage that they are able to ignore much of the image and focus on areas of activity.  
Convolutions may be well suited to this problem as they naturally focus on only small segments of the image meaning the signal-to-noise ratio affecting the PilotNets may be less problematic. 
Kernels capable of detecting dot motion were developed using an evolutionary algorithm. 
These dataset sepecific kernels were then used to transform the DVS recordings into feature maps in which each pixel represented the kernel for which it most highly responded. 
The feature maps were then used as training examples in a fully connected network with the aim being to analyse the performance of the network in predicting an output feature map. 
%Kenels specialised to the datasets were developed, these were then used to preprocess the input/output decayed images to produce feature maps which could then be used to train the network as per normal.
%Kernels  to the datsets were developed and then used to process recordings into training examples.


%TODO Need a clear definition of what the kernels are 
% Things like:
%   - Size
%   - Limits (27) why...

\subsection{Method}
Three major steps were required to move from a DVS recording to a prediction in this study, the final system is illustrated in figure \ref{fig:evoNetStructure}.
First kernels for convolutions were evolved to be specialised to the 8AD dataset using a 1 + 1 hillclimbing algorithm (described in Appendix \ref{ch:evolution}). 
After sufficient evolution they were convolved with the DVS recording to produce feature map training examples.
Finally the feature maps specifying which kernel had responded most strongly for that pixel were fed into a fully connected network which was predicted feature maps at the output.  

\subsubsection{Evolving kernels}
As no standard set of feature kernels to use with event-based data exists these would need to be created.
Previous work developing kernels using an evolutionary algorithm made this a sensible place to start.
In this work a kernel is considered as a matrix with each value being a weight describing how important an event at that position is.
Kernels start randomly initialised and are iteratively updated by permuting kernel weights and convolving the new kernel with some sample data, improvements in kernel performance as measured by a fitness function are kept.
Finer details of the evolutionary algorithm are discussed in Appendix\ref{ch:evolution}.
A set of nine and a set of five kernels were created using this technique.
Motivation for using nine kernels was inspired by the 8AD dataset with anticipation that each kernel would specialise for one of the angles plus one kernel to detect noise.
Five was chosen to see if similar behaviour could be modelled as weighted combinations of less kernels.
A kernel size of 11x11 pixels was chosen as this would capture much of the temporal past (and future) for an accumulation over 33\ms.



\subsubsection{Processing training examples}
Convolving the 9, 11x11 kernels with the 128x128 images gave 9, 128x128 features maps (likewise for the 5 kernels).
Rather than using pooling \textit{within} a feature map as is standard in convolutional neural networks max-pooling was applied \textit{between} the maps. 
That is the result was a single 128x128 map created in which each position was the index of the feature map with the highest output at that pixel.


% TODO How were ties broken?!
% TODO add a picture of what this process looks like, event-data -> decayed image -> kernels -> back on decayed image -> network input and output


\subsubsection{Network design} 
The networks used then resembled those of PilotNet2.
Representing each pixel as the kernel which most strongly responds to it should make predicting future motion simple task for a shallow network to learn.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{evoNetStructure.png}
    \caption{Structure of the Evolutionary Kernels processing pipeline}
    \label{fig:evoNetStructure}
\end{figure}


\subsubsection{Analytic kernels}
Additionally an alternative set of kernels was developed based on the probabilities of event patterns in the training data.
For all samples of a given angle an 11x11 matrix was cropped around each event, the probabilities of events in each position of the matrix was then calculated for that angle giving an analytic kernel.
The process of cropping an 11x11 matrix around events is the same process as discussed in Chapter \ref{ch:attentional}.
These kernels were significantly quicker to compute compared to the evolutionary kernels which required many convolutions of the full dataset for each evolution. 

\subsection{Results}
Using the available evolutionary algorithm proved to be too slow to develop meaningful 11x11 kernels on the large 8AD dataset.
The kernels were not able to converge to a stable point after 14 days of training, example kernels are shown in \ref{fig:unstableKernel}. \textbf{[TODO: add images of kernel state]}
The kernel states after 14 days were applied to the data regardless to see if meaningful results could be achieved. 
Figure \ref{fig:exampleFeatureMap} \textbf{[TODO: example input/feature map pair]} shows an example feature map resulting from the prematurely stopped kernel. 
\textbf{[TODO: Depending on figure used, comment on the performance of the kernel and how clearly the input stimulus is represented]}.

Applying the analytic kernels to the input produced feature maps as shown in figure \ref{fig:analyticFeatureMap}\textbf{[TODO: choose and include an analytic map, discuss image]}.

Figure \ref{fig:evoNetOut} \textbf{[TODO: collect output images into one figure and include]} illustrates that  
% TODO DISCUSSION SECTION
\subsection{Discussion}
 - Algorithm is to blame, needs redesigning but out of scope of thesis
\\ - Also there is an additional problem of a disparity between training and test data
\\ - SHould be okay though because its just the shape we need but still issues because of magnitude of
\\ - white pixels near center vs binary 1's everywhere
\\ - Using the index of the feature map is not informative to the poor network...Maybe should have been converted to a hot vector


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%      CONVOLUTIONAL NN    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{convNet}
%Define it what did it learn and what happened.
%Alternative approach of using evol kerns on full image

\subsection{Aims}
The amount of time required to evolve kernels using the available evolutionary algorithm meant an alternative approach was necessary. 
Directly using a conventional convolutional network represented the logical progression after evolving kernels manually. 
The experimental design remained similar to the evolutionary kernels as described in figure \ref{fig:evoNetStructure}.
The difference being for this study the 128x128 temporally accumulated images were directly used as inputs to the network which was responsible for developing the kernels and feature maps and pooling was done spatially within a feature map rather than between feature maps.
This study should be able to leverage the advantages of convolution networks (e.g. focused feature detectors on smaller parts of the image) whilst still being trainable in reasonable time. 

%Rather than using an evolutionary algorithm to evolve kernels with which to later apply convolutions to the data this can all be done within a Convolutional Neural Network. 
%This network should be able to produce much of the behaviour of the evolved kernels (because it will be designing its own during training) but shouldn't suffer from the slow training time and possible inconsitancys between training and test data.

\subsection{Method}
\label{sec:convMethod}
The network used in this work consisted of an input layer followed by a convolution layer with 9, 11x11 convolutions followed by a 2x2 max pooling layer feeding into a fully connected layer. 
The output layer of the network was differently activated to compare performance. 
Details are outlined in table \ref{tb:convNetdef}.

\begin{table}[h]
\centering
\begin{tabular}{ | l | l | }
    \hline
    Num. Inputs & 16384 \\
    Num. Outputs & 16384 \\
    Num. Hidden Layers & 3 \\
    Fully connected & 64, 1024 units \\
    Layers & Convolutions -\textgreater pooling -\textgreater output \\
    Output Activations & Linear, Sigmoid, ReLU \\
    Loss & Sum Squared Difference, weighted S.S.D. \\
    Learning rule & S.G.D. (back propogation) \\
    Learning rate & 0.5 \\
    Convolution stride & 1 \\
    \hline
\end{tabular}
\caption{Features of convNet}
\label{tb:convNetdef}
\end{table}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{convNetInvariance.png}
    \caption{An example of a convolutional network input invariance and the corresponding fully connected layer features}
    \label{fig:convInputInvariance}
\end{figure}


\subsection{Results}
The convolution networks quickly (\textless 250 epochs) become input invariant.
This is shown in figure \ref{fig:convInputInvariance} in which despite a strong relatively clean signal the network is not able to make a meaningful prediction. 
The mechanism for this invariance can be seen in the weights and biases of the network over the first 5000 epochs.
The weights shift between 3 and -3 while the biases quickly shift towards -3, this example network (ReLU activated) then outputs just zeros.
This trend was consistant across the other convolutional architectures and parameters outlined in table \ref{tb:convNetdef}.


\subsection{Discussion}
Convolutional architectures should have been well suited to solving this sparse signal problem.
The architectures used in this study were able to make any meaningful predictions and quickly learnt to just output a constant zero pattern much like like the PilotNets.
Several factors could have contributed to the poor performance of these networks including signal-to-noise ratio, number of epochs, learning rate or the training data. 

The convolutional networks were believed to have been better able to deal with the signal-to-noise ratio however the ratio may have proved still too high for the networks.
Convolution sizes were chosen to consider this with an 11x11 convolution resonably converying an accumulated past/future over a 33 ms window. 
An 11x11 area may have been too large yet the 6x6 kernels were not able to learn either suggesting there may still be other problems.
The noise in the training data may have proved problematic for learning. 
Each kernel may have specialised to pick up different kinds of noise and as noise is inherently unpredictable the kernels learn to predict zero. 

Networks were trained with 50,000 epochs which when compared with how quickly the network became input invariant was considered sufficient.
This number of epochs may not have been enough, perhaps the network needed more time to fine-tune the weights, this would be unlikely though given the lack of improvement in the first 50,000 epochs. 
The learning rate may have contributed to the network getting stuck in a local minima (outputting just zeros) and trying alternative learning rates may help the network learn.
Other techniques such a momentum \ref{sutskever2013importance} which can assist in learning may help but are left as future work.


% - Why did it perform so badly?? -> signal to noise, but even attentional convolutional fail later... Something inherent to convolutions?
 %- Was 1024 Units too many / not enough?
% - Were kernels comparable to evolved kernels / Analytic kernels?
% - How could this be improved?
% - Was the spacial max-pooling an influence




























